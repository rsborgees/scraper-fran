/**
 * Orchestrator - Coordena todos os scrapers de lojas
 * Total: 17 produtos
 * Distribui√ß√£o: FARM 12, Dress To 1, KJU 1, Live 2, ZZMall 1
 */

const fs = require('fs');
const path = require('path');

const { initBrowser } = require('./browser_setup'); // Necess√°rio para passar browser instancia

// Imports
const { scrapeFarm } = require('./scrapers/farm');
const { scrapeSpecificIds } = require('./scrapers/farm/idScanner'); // NOVO
const { getExistingIdsFromDrive } = require('./driveManager');
const { isDuplicate, normalizeId } = require('./historyManager'); // IMPORTADO PARA FILTRO PREVIO
const {
    buildKjuMessage,
    buildDressMessage,
    buildLiveMessage,
    buildFarmMessage,
    buildZzMallMessage
} = require('./messageBuilder');

async function runAllScrapers(overrideQuotas = null) {
    const allProducts = [];
    const quotas = overrideQuotas || {
        farm: 7,
        dressto: 2,
        kju: 1,
        live: 1,
        zzmall: 1
    };

    // üöÄ SINGLE BROWSER INSTANCE SHARING
    // Inicializa o navegador uma √∫nica vez para todos os scrapers
    const { browser } = await initBrowser();

    try {
        const calculatedTotalTarget = Object.values(quotas).reduce((a, b) => a + b, 0);
        console.log(`üöÄ ORCHESTRATOR: Meta ${calculatedTotalTarget} Itens [F:${quotas.farm} D:${quotas.dressto} K:${quotas.kju} L:${quotas.live} Z:${quotas.zzmall}]`);

        // =================================================================
        // PHASE 1: GOOGLE DRIVE PRIORITY
        // =================================================================
        const driveProducts = [];
        let driveItemsByStore = { farm: [], dressto: [], kju: [], zzmall: [], live: [] };
        let unusedFarmDriveItems = [];

        try {
            if (process.env.GOOGLE_DRIVE_FOLDER_ID) {
                const allDriveItems = await getExistingIdsFromDrive(process.env.GOOGLE_DRIVE_FOLDER_ID);

                // Separar itens por loja
                allDriveItems.forEach(item => {
                    if (item.store && driveItemsByStore[item.store]) {
                        driveItemsByStore[item.store].push(item);
                    }
                });

                console.log(`üìä [Drive] Distribui√ß√£o por loja:`);
                Object.entries(driveItemsByStore).forEach(([store, items]) => {
                    if (items.length > 0) console.log(`   ${store.toUpperCase()}: ${items.length} itens`);
                });

                // FARM Drive Items (√∫nico scraper de ID implementado por enquanto)
                const uniqueFarmItems = new Map();

                driveItemsByStore.farm.forEach(item => {
                    const normId = normalizeId(item.id);
                    // Se j√° existe, damos prefer√™ncia se o novo for favorito
                    if (uniqueFarmItems.has(normId)) {
                        const existing = uniqueFarmItems.get(normId);
                        if (!existing.isFavorito && item.isFavorito) {
                            uniqueFarmItems.set(normId, item);
                        }
                    } else {
                        uniqueFarmItems.set(normId, item);
                    }
                });

                const farmDriveItems = Array.from(uniqueFarmItems.values()).filter(item => {
                    if (item.isFavorito) return true;
                    return !isDuplicate(normalizeId(item.id));
                });

                if (farmDriveItems.length > 0) {
                    // Ordenar por Favorito primeiro e pegar apenas at√© o limite da quota
                    const limitedFarmDriveItems = farmDriveItems
                        .sort((a, b) => (b.isFavorito ? 1 : 0) - (a.isFavorito ? 1 : 0))
                        .slice(0, 50); // Passa mais candidatos para compensar falhas/duplicados

                    // Calculamos a cota dispon√≠vel para usar, mas pegamos mais candidatos para garantir
                    // que se chover duplicado, n√£o ficamos sem.
                    // O `scrapeSpecificIds` respeita o `quotas.farm`.

                    // Reutiliza o browser instanciado
                    const scrapedDriveItems = await scrapeSpecificIds(browser, limitedFarmDriveItems, quotas.farm);
                    scrapedDriveItems.forEach(p => p.message = buildFarmMessage(p, p.timerData));

                    allProducts.push(...scrapedDriveItems);
                    driveProducts.push(...scrapedDriveItems);

                    // SALVAR O RESTO PARA REDISTRIBUI√á√ÉO
                    // Remove os que foram efetivamente 'processados' (enviados) da lista de candidatos
                    const processedIds = new Set(scrapedDriveItems.map(p => normalizeId(p.id)));

                    // Guarda o que sobrou da lista `farmDriveItems` original (n√£o s√≥ da limited)
                    // Filtra o que j√° foi e o que j√° sabemos que √© duplicado (mas o filtro inicial j√° cuidou disso na maioria)
                    unusedFarmDriveItems = farmDriveItems.filter(item => !processedIds.has(normalizeId(item.id)));
                }

                // DRESS TO Drive Items
                const dressToDriveItems = driveItemsByStore.dressto.filter(item => {
                    if (item.isFavorito) return true;
                    return !isDuplicate(normalizeId(item.id));
                });

                if (dressToDriveItems.length > 0) {
                    const { scrapeSpecificIdsDressTo } = require('./scrapers/dressto/idScanner');
                    // Ordenar por Favorito
                    const limitedDressItems = dressToDriveItems
                        .sort((a, b) => (b.isFavorito ? 1 : 0) - (a.isFavorito ? 1 : 0))
                        .slice(0, 50);

                    const scrapedDressItems = await scrapeSpecificIdsDressTo(browser, limitedDressItems, quotas.dressto);
                    scrapedDressItems.forEach(p => p.message = buildDressMessage(p));

                    allProducts.push(...scrapedDressItems);
                    driveProducts.push(...scrapedDressItems);
                }

                // TODO: Implementar idScanner para outras lojas quando necess√°rio (KJU, Live, ZZMall)
            }
        } catch (driveErr) {
            console.error('‚ùå Erro Phase 1 (Drive):', driveErr.message);
        }

        // Ajusta Quotas restantes
        const driveCountFarm = driveProducts.filter(p => p.loja === 'farm').length;
        const remainingQuotaFarm = Math.max(0, quotas.farm - driveCountFarm);

        console.log(`üìä P√≥s-Drive: ${driveCountFarm} itens Farm capturados. Restam ${remainingQuotaFarm} para scraping regular.`);

        // =================================================================
        // PHASE 2: REGULAR SCRAPING
        // =================================================================

        // 1. Scrapes (Passando o objeto browser)
        if (remainingQuotaFarm > 0) {
            try {
                let products = await scrapeFarm(remainingQuotaFarm, false, browser);
                products.forEach(p => p.message = buildFarmMessage(p, p.timerData));
                allProducts.push(...products);
                console.log(`‚úÖ FARM (Regular): ${products.length} msgs geradas`);
            } catch (e) { console.error(`‚ùå FARM Error: ${e.message}`); }
        }

        const driveCountDressTo = driveProducts.filter(p => p.loja === 'dressto').length;
        const remainingQuotaDressTo = Math.max(0, quotas.dressto - driveCountDressTo);

        if (remainingQuotaDressTo > 0) {
            try {
                const { scrapeDressTo } = require('./scrapers/dressto');
                let products = await scrapeDressTo(remainingQuotaDressTo, browser);
                products.forEach(p => p.message = buildDressMessage(p));
                allProducts.push(...products);
                console.log(`‚úÖ DressTo: ${products.length} msgs geradas`);
            } catch (e) { console.error(`‚ùå DressTo Error: ${e.message}`); }
        } else {
            console.log(`‚úÖ DressTo: Cota preenchida pelo Drive (${driveCountDressTo}/${quotas.dressto})`);
        }

        try {
            const { scrapeKJU } = require('./scrapers/kju');
            let products = await scrapeKJU(quotas.kju, browser);
            products.forEach(p => p.message = buildKjuMessage(p));
            allProducts.push(...products);
            console.log(`‚úÖ KJU: ${products.length} msgs geradas`);
        } catch (e) { console.error(`‚ùå KJU Error: ${e.message}`); }

        try {
            const { scrapeZZMall } = require('./scrapers/zzmall');
            let products = await scrapeZZMall(quotas.zzmall, browser);
            products.forEach(p => p.message = buildZzMallMessage(p));
            allProducts.push(...products);
            console.log(`‚úÖ ZZMall: ${products.length} msgs geradas`);
        } catch (e) { console.error(`‚ùå ZZMall Error: ${e.message}`); }

        // 2. LIVE Special Handling (Sets)
        try {
            const { scrapeLive } = require('./scrapers/live');
            let products = await scrapeLive(quotas.live, false, browser);

            let i = 0;
            while (i < products.length) {
                const current = products[i];
                let chunk = [];

                if (current.type === 'onepiece') {
                    // Pe√ßa √∫nica -> Mant√©m objeto original
                    chunk = [current];
                    i++;
                } else {
                    // Par Top + Bottom (qualquer)
                    const next = products[i + 1];
                    if (next && next.type !== 'onepiece') {
                        // MERGE 2 produtos em 1 objeto SET
                        console.log(`   üîó Merging ${current.nome} + ${next.nome}`);

                        const mergedProduct = {
                            ...current,
                            id: `${current.id}_${next.id}`,
                            nome: `${current.nome} + ${next.nome}`,
                            preco: parseFloat((current.preco + next.preco).toFixed(2)),
                            precoOriginal: parseFloat(((current.precoOriginal || current.preco) + (next.precoOriginal || next.preco)).toFixed(2)),
                            // Mant√©m imagem do Top (geralmente mais representativo) ou poderia tentar outra estrat√©gia
                            // User n√£o pediu imagem composta, apenas "n√£o enviar 2 produtos"
                            imageUrl: current.imageUrl,
                            imagePath: current.imagePath,
                            link: current.url, // Link do Top
                            loja: 'live',
                            set: true
                        };

                        chunk = [mergedProduct];
                        i += 2;
                    } else {
                        // √ìrf√£o (Top/Bottom sem par) - Envia single ou descarta?
                        // Se n√£o tiver par, envia single.
                        chunk = [current];
                        i++;
                    }
                }

                // Gera mensagem e adiciona ao output final
                if (chunk.length > 0) {
                    // Se for merge set, s√≥ tem 1 item no chunk
                    const msg = buildLiveMessage(chunk);
                    chunk.forEach(p => p.message = msg);
                    allProducts.push(...chunk);
                }
            }
            console.log(`‚úÖ LIVE: ${products.length} produtos processados`);
        } catch (e) { console.error(`‚ùå LIVE Error: ${e.message}`); }

        // 3. REDISTRIBUI√á√ÉO (Garantir 12 produtos)
        let totalTarget = Object.values(quotas).reduce((a, b) => a + b, 0);
        let gap = totalTarget - allProducts.length;

        if (gap > 0) {
            console.log(`\n‚öñÔ∏è Cota n√£o atingida (${allProducts.length}/${totalTarget}). Lacuna de ${gap} produtos.`);

            // STRATEGY 1: CHECK REMAINING DRIVE ITEMS
            if (unusedFarmDriveItems.length > 0) {
                console.log(`\nüöô Prioridade Redistribui√ß√£o: Usando ${unusedFarmDriveItems.length} itens do Drive restantes...`);

                try {
                    // Pega apenas o necess√°rio para fechar o gap
                    const driveFillCandidates = unusedFarmDriveItems.slice(0, gap + 2); // margem de seguran√ßa
                    console.log(`   üîé Tentando recuperar IDs: ${driveFillCandidates.map(i => i.id).join(', ')}`);

                    const driveFilledProducts = await scrapeSpecificIds(browser, driveFillCandidates, gap);
                    console.log(`   ‚úÖ Retornados do Drive-Scraper: ${driveFilledProducts.length} itens.`);

                    driveFilledProducts.forEach(p => p.message = buildFarmMessage(p, p.timerData));

                    // Add unique only
                    const alreadyPickedIds = new Set(allProducts.map(p => p.id));
                    const newDriveItems = driveFilledProducts.filter(p => !alreadyPickedIds.has(p.id));

                    if (newDriveItems.length === 0 && driveFilledProducts.length > 0) {
                        console.log(`   ‚ö†Ô∏è Todos os itens recuperados j√° estavam na lista principal.`);
                    }

                    allProducts.push(...newDriveItems);
                    gap = totalTarget - allProducts.length;

                    console.log(`‚ôªÔ∏è Redistribui√ß√£o (Drive): +${newDriveItems.length} itens.`);
                } catch (driveRedistErr) {
                    console.error(`‚ùå Erro Redistribui√ß√£o Drive: ${driveRedistErr.message}`);
                }
            } else {
                console.log(`\n‚ö†Ô∏è Sem itens 'unusedFarmDriveItems' dispon√≠veis para redistribui√ß√£o.`);
            }

            // STRATEGY 2: GENERIC SCRAPE (FALLBACK DO FALLBACK)
            if (gap > 0) {
                console.log(`\nüîÑ Preenchendo lacuna restante (${gap}) com FARM (Gen√©rico)...`);

                let attempts = 0;
                const maxAttempts = 2;

                while (gap > 0 && attempts < maxAttempts) {
                    attempts++;
                    try {
                        const { scrapeFarm } = require('./scrapers/farm');
                        let extraProducts = await scrapeFarm(gap + 1, false, browser);

                        const alreadyPickedIds = new Set(allProducts.map(p => p.id));
                        const filteredExtra = extraProducts.filter(p => !alreadyPickedIds.has(p.id)).slice(0, gap);

                        filteredExtra.forEach(p => p.message = buildFarmMessage(p, p.timerData));
                        allProducts.push(...filteredExtra);

                        gap = totalTarget - allProducts.length;
                        console.log(`‚ôªÔ∏è Redistribui√ß√£o (Gen√©rica): +${filteredExtra.length} produtos`);
                    } catch (e) {
                        console.error(`‚ùå Falha na redistribui√ß√£o gen√©rica (tentativa ${attempts}): ${e.message}`);
                        break;
                    }
                }
            }
        }

        console.log('\n==================================================');
        console.log(`RESULTADO FINAL: ${allProducts.length}/${totalTarget} produtos coletados`);
        console.log('Todas as mensagens foram geradas com sucesso.');
        console.log('==================================================');

        return allProducts;

    } catch (error) {
        console.error(`‚ùå Erro no Orchestrator: ${error.message}`);
        return allProducts;
    } finally {
        if (browser) {
            console.log('üîí Encerrando Navegador Mestre...');
            await browser.close();
        }
    }
}

module.exports = { runAllScrapers };
