# ğŸ›ï¸ Multi-Store Scraper System

Sistema automatizado de scraping para 5 lojas de moda com agendamento diÃ¡rio e integraÃ§Ã£o webhook.

## ğŸš€ Quick Start

### **1. InstalaÃ§Ã£o**
```bash
npm install
```

### **2. Executar Scraper Manualmente**
```bash
node index.js
```

### **3. Dashboard Web (Iniciar & Monitorar)**
```bash
npm start
# Acesse: http://localhost:3000
```

### **4. Agendamento AutomÃ¡tico (7h AM)**
```bash
npm run scheduler
```

### **5. Teste Imediato (sem aguardar 7h)**
```bash
npm run scheduler:test
```

---

## ğŸ“Š Sistema

- **Total de Produtos**: 120
- **Lojas**: FARM (84), Dress To (18), KJU (6), Live (6), ZZMall (6)
- **Agendamento**: DiÃ¡rio Ã s 7h da manhÃ£ (horÃ¡rio de BrasÃ­lia)
- **Webhook**: POST automÃ¡tico dos dados coletados

---

## ğŸ“‚ Estrutura

```
scrapping/
â”œâ”€â”€ index.js              # ExecuÃ§Ã£o Ãºnica do scraper
â”œâ”€â”€ server.js             # Dashboard web (porta 3000)
â”œâ”€â”€ cronScheduler.js      # Agendador diÃ¡rio + webhook
â”œâ”€â”€ orchestrator.js       # CoordenaÃ§Ã£o de todos scrapers
â”œâ”€â”€ imageDownloader.js    # Download de imagens (Playwright)
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ farm/            # Scraper FARM (84 produtos)
â”‚   â”œâ”€â”€ dressto/         # Scraper Dress To (18 produtos)
â”‚   â”œâ”€â”€ kju/             # Scraper KJU (6 produtos)
â”‚   â”œâ”€â”€ live/            # Scraper Live (6 produtos)
â”‚   â””â”€â”€ zzmall/          # Scraper ZZMall (6 produtos)
â””â”€â”€ public/
    â””â”€â”€ index.html       # Interface do dashboard
```

---

## ğŸ”§ Comandos

| Comando | O que faz |
|---------|-----------|
| `npm start` | Inicia dashboard web em http://localhost:3000 |
| `npm run scheduler` | Ativa agendamento diÃ¡rio (7h AM) |
| `npm run scheduler:test` | Executa scraping imediato + webhook |
| `node index.js` | Executa scraping Ãºnico (sem webhook) |

---

## ğŸ“¤ Webhook Configuration

**Endpoint:**
```
POST https://n8n-azideias-n8n.ncmzbc.easypanel.host/webhook/1959ec08-24d1-4402-b458-8b56b8211caa
```

**Payload:**
```json
{
  "timestamp": "2025-12-29T07:00:00.000Z",
  "totalProducts": 120,
  "products": [...],
  "summary": {
    "farm": 84,
    "dressto": 18,
    "kju": 6,
    "live": 6,
    "zzmall": 6
  }
}
```

---

## ğŸ–¥ï¸ Deploy (Manter Rodando 24/7)

### **OpÃ§Ã£o 1: PM2 (Recomendado)**

```bash
# Instalar PM2
npm install -g pm2

# Iniciar scheduler
pm2 start cronScheduler.js --name scraper

# Auto-start no boot
pm2 startup
pm2 save

# Monitorar
pm2 logs scraper
pm2 status
```

### **OpÃ§Ã£o 2: Docker**

```bash
docker build -t scraper .
docker run -d --restart always scraper
```

---

## ğŸ“ Features

âœ… **Scraping AutomÃ¡tico**: 5 lojas, 120 produtos/dia  
âœ… **Download de Imagens**: 1 imagem por produto (Playwright)  
âœ… **Regras de PreÃ§o**: FARM (promo real), Outras (preÃ§o original)  
âœ… **Agendamento**: ExecuÃ§Ã£o diÃ¡ria Ã s 7h AM  
âœ… **Webhook**: POST automÃ¡tico dos dados  
âœ… **Dashboard**: Interface web para monitoramento  
âœ… **Logs**: Console em tempo real com cÃ³digo de cores  

---

## ğŸ› ï¸ Tecnologias

- **Node.js**
- **Playwright** (Browser automation)
- **Express** (Web server)
- **node-cron** (Scheduler)
- **axios** (HTTP client)

---

## ğŸ“š DocumentaÃ§Ã£o Completa

- [Scheduler Guide](file:///.gemini/antigravity/brain/.../scheduler_guide.md)
- [Dashboard Walkthrough](file:///.gemini/antigravity/brain/.../scraper_dashboard_walkthrough.md)

---

## âš¡ Performance

- **Tempo mÃ©dio**: ~15-20 minutos para 120 produtos
- **Concurrent scrapers**: Sim (5 lojas em paralelo)
- **Error handling**: Retry automÃ¡tico + log detalhado
- **Images**: Download em paralelo com scraping

---

## ğŸ“ Troubleshooting

**Webhook nÃ£o responde?**
```bash
npm run scheduler:test  # Testa imediatamente
```

**Scraper nÃ£o agenda?**
```bash
pm2 logs scraper  # Verifica logs
```

**Imagens nÃ£o baixam?**
- Verifique permissÃµes da pasta `downloads/`
- Rode em modo teste para ver erros especÃ­ficos

---

## ğŸ¯ Status

âœ… **Pronto para ProduÃ§Ã£o**

Sistema completo e testado, pronto para deploy 24/7.
